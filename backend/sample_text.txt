I am deeply interested in the project LLM-assisted Geospatial Data Analysis and GUI Development for Remote Sensing Algorithms. Its uniqueness lies in combining advanced geospatial workflows with natural language interaction, making complex analyses more intuitive and accessible. To explore this idea, I developed a demo project called SnowSense (Demo video link[https://drive.google.com/file/d/1dijzZFlcI7szTCEMqHaNlqZLATeD_3rJ/view?usp=drivesdk], GitHub code link[https://github.com/Mounika-Alwar/SnowSense]), which integrates manual and automated modes of interaction.

In manual mode, users can select regions like the Siachen Glacier or European Alps, visualize RGB composites, clip areas of interest, and perform NDSI-based snow analysis—including wet and dry snow classification. Results are presented both numerically and through interactive Plotly charts. In automated mode, users simply type prompts like “Fetch Siachen glacier and analyse it”, and the system retrieves, processes, and shows results. This was achieved using Gemini and LangChain in the backend, with Python libraries such as Rasterio, GeoPandas, and Xarray, deployed via Streamlit. SnowSense reinforced my belief that intuitive tools can democratize geospatial analysis, especially in cryospheric studies where remote sensing data plays a vital role.

My interest in geospatial science began with a forest fire dataset I built for Uttarakhand (April 2022 – June 2024), integrating ERA5 weather data, USGS DEMs, ESA WorldCover, and NASA FIRMS fire records. I aligned spatial-temporal resolutions, engineered features like humidity and wind speed, and created severity classes for over 75,000 spatio-temporal records. This experience taught me how to manage complex preprocessing pipelines and sparked my passion for applying AI to geospatial challenges—an area I understand is central to your research group’s work on environmental and cryospheric systems.

Beyond geospatial work, I’ve built end-to-end projects across domains, from sentiment analysis of Alexa reviews to neural style transfer, weather forecasting, and GPUlympics, a GPU performance dashboard deployed using FastAPI, Streamlit, and Docker. At the GDG ML Hackathon, I built an employee prediction model in under three hours, which was recognized among the best solutions. These experiences taught me to work efficiently under constraints while maintaining clarity and precision.

Technically, I’m proficient in Python, ML/DL, geospatial libraries (Rasterio, GeoPandas), GUI frameworks (Streamlit), and LLM frameworks (Gemini API, LangChain). I’ve also completed the Machine Learning and Deep Learning specializations from deeplearning.ai, which provided a strong theoretical foundation to complement my practical work.

In the long term, I aim to contribute to research at the intersection of AI and geospatial science, building tools that are both scientifically rigorous and widely usable. This internship at IIT Bombay, particularly under your guidance, represents a meaningful step in that journey. It offers the chance to learn from distinguished mentors, gain exposure to cryospheric and hydrological applications, and contribute to impactful geospatial tools. SnowSense was a small beginning; this internship would allow me to take the next leap with direction and expertise from your lab.




I have undertaken several projects that bridge AI, geospatial data, and user-centric applications. Notably, I developed SnowSense, a prototype platform that combines geospatial libraries, LangChain, and Streamlit to perform snow analysis through both graphical and prompt-driven interfaces. I also built GPUlympics, an interactive GPU performance dashboard deployed using FastAPI, Streamlit, and Docker, along with applications such as a Neural Style Transfer system using TensorFlow Hub, a Weather Prediction tool integrating OpenWeatherMap data with regression models and visualizations, and a Sentiment Analysis pipeline for Alexa reviews employing multiple machine learning algorithms. Earlier projects include a word-based psychological profiling tool and a Cat vs Dog classifier implemented from scratch. Across these works, my focus has been on end-to-end development—designing solutions that are not only technically sound but also fully deployed, reproducible, and accessible for real-world use.


My technical expertise spans Python, machine learning and deep learning, LangChain, Gemini API, Streamlit, FastAPI, Docker, and geospatial libraries such as Rasterio, GeoPandas, and Xarray. I have strengthened my theoretical foundation by completing the Machine Learning and Deep Learning Specializations from deeplearning.ai. Beyond technical skills, I maintain a strong inclination toward end-to-end project deployment ensuring that the solutions I build are practical, reproducible, and accessible.